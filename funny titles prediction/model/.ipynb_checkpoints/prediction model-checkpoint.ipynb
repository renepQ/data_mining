{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4774ebe235f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while(1002//10!=0):\n",
    "    i=i+1\n",
    "    \n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim\n",
    "word2 = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files, set up folder, put files into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: ../data/train.csv\n",
    "# test data:     ../data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9652\n"
     ]
    }
   ],
   "source": [
    "filepath = '../data/train.csv'\n",
    "dataframe = pd.read_csv(filepath)\n",
    "print(len(dataframe))\n",
    "# print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 6756\n",
      "validation set size: 2896\n",
      "         id                                           original          edit  \\\n",
      "8817  14932  \" <System/> safeguards are lacking \" , quote f...     Deodorant   \n",
      "2481  12134  If Trump wants to use this memo to fire Rosens...       writing   \n",
      "2918   6259  Donald Trump Jr. may well have committed a fed...          pray   \n",
      "3982   5133  After healthcare failures , senior GOP senator...        coffee   \n",
      "7372   1278         Obama 's letters to college <girlfriend/>      boyfriend   \n",
      "1551  11255  Navy SEAL Who Killed Bin Laden Calls Trump 's ...         Float   \n",
      "7573   5467  Paul Manafort asked a judge to let him go to t...          Iraq   \n",
      "1562  10407  Russian <hackers/> hunt hi-tech secrets , expl...         bears   \n",
      "991    9633  American <kids/> are 70 percent more likely to...    terrorists   \n",
      "2596  11628  House <Speaker/> Paul Ryan was the biggest fra...       Painter   \n",
      "4466  14156  Senate blocks war powers resolution for <Yemen/>       children   \n",
      "3800  13764  German political <limbo/> threatens European r...         tango   \n",
      "758    2179  Search » U.S. Edition + Russia urged to <ban/>...       embrace   \n",
      "2556   3065  Trump 's State Department denies <jobs/> to wi...    hamburgers   \n",
      "5124  12871  Bashar al-Assad and Vladimir Putin Hug and Dec...     slapstick   \n",
      "1849   2763  Trump administration moves to tighten squeeze ...           man   \n",
      "957    5874  Full Text : Jared Kusher 's prepared <statemen...       whopper   \n",
      "5265  10781  Paul Ryan threw Republican <senators/> under t...          cops   \n",
      "3305   2594  China seizes control of <insurance/> giant Anbang         human   \n",
      "6499   2728  Donald Trump 's inauguration was full of promi...      distaste   \n",
      "3742  12111  New Dashcam Video Shows Philando Castile Infor...        Kitten   \n",
      "1537  13156  Will Sweden Become the First <Country/> to Go ...           bum   \n",
      "7872  11151  Bizarre GOP infighting over federal <lands/> :...    milkshakes   \n",
      "6367  13269  The Coca-Cola invasion is <causing/> Mexico ’s...   celebrating   \n",
      "7043   7435    Tillerson thanks <Mexico/> for help with Harvey          self   \n",
      "6291   1084  North Korea Accuses U.S. of Plot to Assassinat...          bees   \n",
      "116   13357  “ It ’s painfully obvious \" Mueller will charg...      plumbing   \n",
      "3173  14317  Trump ’s own <voters/> are now warning him aga...          toes   \n",
      "6183   9117  Trump has pledged $ 1 million to Harvey <relie...           pie   \n",
      "5919   9936  Week 53 : Trump Goes <Spy/> Hunting and Gets S...         house   \n",
      "...     ...                                                ...           ...   \n",
      "7865   8309  Trump likely to <visit/> FBI headquarters in c...      demolish   \n",
      "8422   5056  U.S. Politics Are Rigged . It 's Time For a Sm...      luncheon   \n",
      "6590   7905  Trump Wades Deeper Into Alabama Primary At <Ca...    Underwater   \n",
      "4137   5269  Pakistan Prime Minister Nawaz Sharif disqualif...        sports   \n",
      "216    4138  Treasury <watchdog/> probes possible leak of T...    prostitute   \n",
      "3394   4885  Spiritual Sedona : the <Arizona/> town burstin...         ghost   \n",
      "3131   7083                      Yet another <mystery/> motive   unmotivated   \n",
      "9038    497  Israel : US-Led Strikes enforce Red Line on <s...         paper   \n",
      "2821   7283  Bitcoin just tanked below $ 10,000 after SEC s...         scams   \n",
      "5803   5939  NASA Says Pence Was OK to Touch <Hardware/> De...        monkey   \n",
      "2163   1141  Erick Erickson : Trump 's <Russia/> Leak Is ' ...       Tanning   \n",
      "8237  13818  ' We 're preparing for the worst ' : ' alt-rig...          orgy   \n",
      "7109  10951  AP Fact Check : How ’s Trump ’s <border/> wall...       kitchen   \n",
      "7883    849  A top GOP <senator/> just showed why tax refor...     librarian   \n",
      "1478     44   <DEMOCRATS/> ARE ' MOVING ON ' FROM HILLARY C...        Humans   \n",
      "3336     98  Sanders ’ Campaign Staff , Delegates , And Vol...      Children   \n",
      "4060  10919       Trump defends $ 1.5 trillion <tax/> cut bill         teddy   \n",
      "1678   3478  Trump watched part of the <eclipse/> without v...         movie   \n",
      "2443   4372  Officials : Young Afghans trafficked to Pakist...         cover   \n",
      "733    8600  Trump Filed Extension for 2017 <Tax/> Return ,...         space   \n",
      "7694   8713  Mexico Sends Top Official to California Help I...       Showers   \n",
      "5971   3378  If weed is no longer a crime , why are <people...        plants   \n",
      "8006   4648  Trump decries ' alt-left ' in Charlottesville ...  conservatism   \n",
      "4368   1974  Kushners , Brookfield Near Deal on Troubled 66...        demons   \n",
      "5032   7131  Rob Porter is no <anomaly/> : He ’s the perfec...         human   \n",
      "2815   9905  Business leaders quit Trump <panel/> ; he hits...     bandwagon   \n",
      "2398  10051  Hundreds Of Thousands Of ' Missing ' Educators...       bananas   \n",
      "602    6579  Clinton Wo n't Rule Out Questioning 2016 <Elec...          song   \n",
      "9483   7565  The Senate ’s <immigration/> debate , starting...         lunch   \n",
      "4904   9678  On China ’s Weibo , It ’s Forbidden to Disagre...         dance   \n",
      "\n",
      "          grades  meanGrade  \n",
      "8817       21111        1.2  \n",
      "2481       11000        0.4  \n",
      "2918       32210        1.6  \n",
      "3982       21110        1.0  \n",
      "7372       31000        0.8  \n",
      "1551       32110        1.4  \n",
      "7573       11100        0.6  \n",
      "1562       32110        1.4  \n",
      "991        32200        1.4  \n",
      "2596       11100        0.6  \n",
      "4466       11000        0.4  \n",
      "3800       11100        0.6  \n",
      "758        11100        0.6  \n",
      "2556       21000        0.6  \n",
      "5124       22100        1.0  \n",
      "1849       11100        0.6  \n",
      "957        32111        1.6  \n",
      "5265       21000        0.6  \n",
      "3305       31000        0.8  \n",
      "6499       33000        1.2  \n",
      "3742       21110        1.0  \n",
      "1537       20000        0.4  \n",
      "7872       11100        0.6  \n",
      "6367       11000        0.4  \n",
      "7043       22110        1.2  \n",
      "6291       32200        1.4  \n",
      "116        31110        1.2  \n",
      "3173       32110        1.4  \n",
      "6183       21100        0.8  \n",
      "5919       32111        1.6  \n",
      "...          ...        ...  \n",
      "7865       33110        1.6  \n",
      "8422       21000        0.6  \n",
      "6590       31110        1.2  \n",
      "4137       11000        0.4  \n",
      "216        20000        0.4  \n",
      "3394       21000        0.6  \n",
      "3131           0        0.0  \n",
      "9038       21000        0.6  \n",
      "2821       11000        0.4  \n",
      "5803       32200        1.4  \n",
      "2163       32211        1.8  \n",
      "8237       11100        0.6  \n",
      "7109       22111        1.4  \n",
      "7883           0        0.0  \n",
      "1478       22100        1.0  \n",
      "3336       22000        0.8  \n",
      "4060       11000        0.4  \n",
      "1678       11100        0.6  \n",
      "2443       21000        0.6  \n",
      "733        11100        0.6  \n",
      "7694       32221        2.0  \n",
      "5971       33110        1.6  \n",
      "8006       22100        1.0  \n",
      "4368       33211        2.0  \n",
      "5032       11110        0.8  \n",
      "2815       31000        0.8  \n",
      "2398       32110        1.4  \n",
      "602        10000        0.2  \n",
      "9483  3322110000        1.2  \n",
      "4904       32111        1.6  \n",
      "\n",
      "[6756 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7 # 70% for training, 30% for validation\n",
    "random_seed = 100 # a fixed random seed allows fixed random runs (for controlled debugging). set to None to be random.\n",
    "all_dataframe=dataframe\n",
    "train_dataframe = dataframe.sample(frac= train_ratio, random_state=100) \n",
    "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
    "print('training set size:', len(train_dataframe))\n",
    "print('validation set size:', len(valid_dataframe))\n",
    "print(train_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also load test data (no splitting needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set size: 2413\n"
     ]
    }
   ],
   "source": [
    "test_filepath = '../data/test.csv'\n",
    "test_dataframe = pd.read_csv(test_filepath)\n",
    "print('test set size:', len(test_dataframe))\n",
    "# print(test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the trivial baseline: always predicting the average meanGrade (of training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out prediction targets: mean grades \n",
    "train_Y = train_dataframe['meanGrade']\n",
    "valid_Y = valid_dataframe['meanGrade']\n",
    "all_Y=all_dataframe['meanGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average meanGrade on training set: 0.9339303335306821\n",
      "RMSE on validation set: 0.5879321000863943\n"
     ]
    }
   ],
   "source": [
    "# compute average of a list of numbers: np.mean\n",
    "train_Y_avg = np.mean(train_dataframe['meanGrade'])\n",
    "print('average meanGrade on training set:', train_Y_avg)\n",
    "\n",
    "# make a list filled with train_Y_avg, essentially predicting the same number for all lines in validation set\n",
    "avg_pred_valid = [train_Y_avg for i in range(len(valid_dataframe))]\n",
    "\n",
    "# compute root mean squared error (RMSE) of this prediction on validation set\n",
    "rmse = np.sqrt(mean_squared_error(valid_Y, avg_pred_valid))\n",
    "print('RMSE on validation set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: write out prediction values into a csv format file\n",
    "# params:\n",
    "#     df: dataframe, where each row is a test example, with column 'id' as data id\n",
    "#     pred: a list or 1-d array of prediction values\n",
    "#     filepath: the output file path\n",
    "# return:\n",
    "#     None\n",
    "\n",
    "def write_test_prediction(df, pred, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        outfile.write('{},{}\\n'.format('id', 'pred'))\n",
    "        for index, row in df.iterrows():\n",
    "            outfile.write('{},{}\\n'.format(row['id'], pred[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list filled with train_Y_avg, essentially predicting the same number for all lines in test set\n",
    "avg_pred_test = [train_Y_avg for i in range(len(test_dataframe))]\n",
    "write_test_prediction(test_dataframe, avg_pred_test, '../data/average_constant_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature extractor from training data (here we use a TFIDF extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get entire raw text in training corpus, including title and edit words (for learning vocabulary and IDF)\n",
    "# params:\n",
    "#     df: dataframe, with 'original' and 'edit' columns\n",
    "# return:\n",
    "#     corpus: a list of text strings, each is a concatenation of original text and edit word on each line\n",
    "import re \n",
    "\n",
    "def get_raw_text(df):\n",
    "    corpus = []\n",
    "    for index, row in df.iterrows():\n",
    "        title = row['original'].replace('<', '').replace('/>', '')\n",
    "        edit = row['edit']\n",
    "        corpus.append( title + ' ' + edit )\n",
    "    return corpus\n",
    "        #pattern = re.compile(r'[<](.*?)[/][>]')\n",
    "        #new_row=pattern.sub(row['edit'] , row['original'])\n",
    "       # corpus.append( row['edit'] )\n",
    "    #return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = get_raw_text(all_dataframe)\n",
    "\n",
    "#vectorizer = TfidfVectorizer(stop_words = None).fit(train_corpus)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = None).fit(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features of both training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: separate each title into (original_word, context), where context = title text without original word \n",
    "# params:\n",
    "#     df: dataframe, with 'original' and 'edit' columns\n",
    "# return:\n",
    "#     original_words: a list of original word strings before editing\n",
    "#     contexts:       a list of context strings \n",
    "\n",
    "def separate_original_word_from_title(df):\n",
    "    original_words = []\n",
    "    contexts = []\n",
    "    for index, row in df.iterrows():\n",
    "        title = row['original']\n",
    "        start_position = title.find('<')\n",
    "        end_position = title.find('/>')\n",
    "        original_words.append(title[start_position+1 : end_position])\n",
    "        contexts.append(title[:start_position] + title[end_position+2 :])\n",
    "    return original_words, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct sparse feature matrix\n",
    "# params:\n",
    "#     df: dataframe, with 'original' and 'edit' columns\n",
    "#     vectorizer: sklearn text vectorizer, either TfidfVectorizer or Countvectorizer \n",
    "# return:\n",
    "#     M: a sparse feature matrix that represents df's textual information (used by a predictive model)\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def construct_feature_matrix(df_raw, vectorizer,model):\n",
    "    edited_words = df_raw['edit'].tolist()\n",
    "    # here the dimensionality of X is len(df) x |V|\n",
    "    feature_copus= vectorizer.transform(edited_words)\n",
    "    original_words=[]\n",
    "    for index, row in df_raw.iterrows():\n",
    "        title = row['original']\n",
    "        start_position = title.find('<')\n",
    "        end_position = title.find('/>')\n",
    "        original_words.append(title[start_position+1 : end_position])\n",
    "    df = pd.DataFrame({'edited_words': edited_words, 'original_words':original_words})\n",
    "    #create new corpus\n",
    "    corpus = []\n",
    "    for index, row in df_raw.iterrows():\n",
    "        pattern = re.compile(r'[<](.*?)[/][>]')\n",
    "        new_row=pattern.sub(row['edit'] , row['original'])\n",
    "        corpus.append( row['edit'] )\n",
    "    #create feature_distance\n",
    "    feature_distances=[]\n",
    "    for index, row in df.iterrows():\n",
    "        if(row[\"edited_words\"] in model.vocab):\n",
    "            vector1=model[row[\"edited_words\"]]\n",
    "        else:\n",
    "            vector1=[1]*300\n",
    "        if(row[\"original_words\"] in model.vocab):\n",
    "            vector2=model[row[\"original_words\"]]\n",
    "        else:\n",
    "            vector2=[1]*300\n",
    "        row=np.dot(vector1,vector2)/(np.linalg.norm(vector1)*(np.linalg.norm(vector2)))\n",
    "        feature_distances.append(row)\n",
    "    \n",
    "    # create_matrix\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from scipy.sparse import hstack\n",
    "    feature_distances_scale=scale(feature_distances)\n",
    "    \n",
    "    feature_distances_2 = np.array(feature_distances_scale)\n",
    "    feature_distances_3 = csr_matrix(feature_distances_2)\n",
    "    feature_distances_4 = feature_distances_3.transpose()\n",
    "    matrix2 = hstack([feature_copus, feature_distances_4])\n",
    "    # construct_length\n",
    "                                  \n",
    "    feature_joke_length=[]\n",
    "    for joke in corpus:\n",
    "        length=len(joke)\n",
    "        feature_joke_length.append(length)\n",
    "        \n",
    "    feature_joke_length_scale=scale(feature_joke_length)\n",
    "    feature_joke_length_2 = np.array(feature_joke_length_scale)\n",
    "    feature_joke_length_3 = csr_matrix(feature_joke_length_2)\n",
    "    feature_joke_length_4 = feature_distances_3.transpose()\n",
    "    matrix3 = hstack([matrix2, feature_joke_length_4])\n",
    "    # construct_position\n",
    "    feature_position=[]\n",
    "    for index, row in df_raw.iterrows():\n",
    "        pos=row['original'].find('\\>')\n",
    "        feature_position.append(pos)\n",
    "    \n",
    "    feature_pos_scale=scale(feature_position)\n",
    "\n",
    "    feature_pos_scale_2 = np.array(feature_pos_scale)\n",
    "    feature_pos_scale_3 = csr_matrix(feature_pos_scale_2)\n",
    "    feature_pos_scale_4 = feature_pos_scale_3.transpose()\n",
    "    new_matrix=matrix = hstack([matrix3, feature_pos_scale_4])\n",
    "    return new_matrix\n",
    "\n",
    "# Construct feature matrices for training and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = construct_feature_matrix(train_dataframe, vectorizer, word2)\n",
    "valid_X = construct_feature_matrix(valid_dataframe, vectorizer, word2)\n",
    "test_X = construct_feature_matrix(test_dataframe, vectorizer, word2)\n",
    "all_X=construct_feature_matrix(all_dataframe, vectorizer, word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on training set, evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear regression model. It's called \"ridge regression\" model here\n",
    "# because it can further alleviates overfitting using so-called L2 regularization,\n",
    "# with regularization alpha = 1\n",
    "\n",
    "model = Ridge(alpha=5).fit(train_X, train_Y)\n",
    "#model = Ridge(alpha=4).fit(all_X, all_Y)\n",
    "#model= linear_model.Lasso(alpha=0.1).fit(all_X, all_Y)\n",
    "#model= linear_model.LinearRegression().fit(train_X, train_Y)\n",
    "#model= linear_model.LinearRegression().fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set: 0.5635414182000094\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "valid_Y_hat = model.predict(valid_X)\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(valid_Y, valid_Y_hat))\n",
    "print('RMSE on validation set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 0.4920567824376471\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on training set: \n",
    "# expect to see unrealistically good performance! (for RMSE: lower is better)\n",
    "# unrealistic because YOUR MODEL IS TRAINED ON EXACTLY THESE DATA!\n",
    "# It gives the best validation/test performance you could hope to achieve using this model.\n",
    "\n",
    "train_Y_hat = model.predict(train_X)\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(train_Y, train_Y_hat))\n",
    "print('RMSE on training set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model on test data, write out prediction results to a csv file\n",
    "test_Y_hat = model.predict(test_X)\n",
    "write_test_prediction(test_dataframe, test_Y_hat, '../data/version9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate what the model has learned and where it failed (A.K.A. error analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         ... -0.02453082 -0.02453082\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at learned parameters (for linear model: weight of each dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a mapping: word -> learned weight of this word\n",
    "feature_weight = {}\n",
    "for word, idx in vectorizer.vocabulary_.items():\n",
    "    feature_weight[word] = model.coef_[idx]\n",
    "# print(feature_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hair 0.7074215389134537\n",
      "haircut 0.5884081295767554\n",
      "toupees 0.5848305981264859\n",
      "underwear 0.5835137539229953\n",
      "toupee 0.5801117443171588\n",
      "tanning 0.5490779471863392\n",
      "hairstyle 0.47337087212092377\n",
      "acid 0.4428147430392513\n",
      "prostitutes 0.4333063052164833\n",
      "kiss 0.40941159805503463\n"
     ]
    }
   ],
   "source": [
    "# words positively correlate with funniness (top ones)\n",
    "for k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = True)[:10]:\n",
    "     print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hates -0.3346565046388396\n",
      "fires -0.33239404557753777\n",
      "energy -0.2986171678098163\n",
      "give -0.2843336732728136\n",
      "pay -0.28109566691900595\n",
      "loves -0.27704495202621404\n",
      "clock -0.269095484845311\n",
      "border -0.267169019051843\n",
      "tent -0.26368965405833567\n",
      "computer -0.2571261191743115\n"
     ]
    }
   ],
   "source": [
    "# words negatively correlate with funniness (top ones)\n",
    "for k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = False)[:10]:\n",
    "     print (k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
